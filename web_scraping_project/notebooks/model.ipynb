{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "221 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "319 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\SEBPE\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70492278 0.70423824 0.70465068\n",
      " 0.70187723 0.70050079 0.70113378 0.69071357 0.69091775 0.69120178\n",
      " 0.69895617 0.69861629 0.69894176 0.69814418 0.6986812  0.69840046\n",
      " 0.68839812 0.68877401 0.6894765  0.68550839 0.68541586 0.6852195\n",
      " 0.68550839 0.68541586 0.6852195  0.68234818 0.68192551 0.68240478\n",
      " 0.70492278 0.70423824 0.70465068 0.70187723 0.70050079 0.70113378\n",
      " 0.69071357 0.69091775 0.69120178 0.69895617 0.69861629 0.69894176\n",
      " 0.69814418 0.6986812  0.69840046 0.68839812 0.68877401 0.6894765\n",
      " 0.68550839 0.68541586 0.6852195  0.68550839 0.68541586 0.6852195\n",
      " 0.68234818 0.68192551 0.68240478        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73242604 0.73432781 0.73416263 0.72317206 0.7246497  0.72513236\n",
      " 0.70904117 0.70989534 0.71014752 0.72116201 0.72097259 0.72127067\n",
      " 0.72128116 0.71967409 0.71989697 0.70358206 0.70350942 0.70389551\n",
      " 0.6957836  0.69470043 0.69423405 0.6957836  0.69470043 0.69423405\n",
      " 0.69173002 0.69169657 0.69191848 0.73242604 0.73432781 0.73416263\n",
      " 0.72317206 0.7246497  0.72513236 0.70904117 0.70989534 0.71014752\n",
      " 0.72116201 0.72097259 0.72127067 0.72128116 0.71967409 0.71989697\n",
      " 0.70358206 0.70350942 0.70389551 0.6957836  0.69470043 0.69423405\n",
      " 0.6957836  0.69470043 0.69423405 0.69173002 0.69169657 0.69191848\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.72964982 0.73184012 0.73260131\n",
      " 0.7254366  0.72572495 0.72654448 0.70889405 0.70992683 0.7104871\n",
      " 0.72130127 0.72098809 0.72145202 0.72093292 0.71965973 0.71986049\n",
      " 0.70377549 0.70350466 0.70386723 0.69575313 0.69469443 0.69420568\n",
      " 0.69575313 0.69469443 0.69420568 0.69172604 0.69167134 0.69194733\n",
      " 0.72964982 0.73184012 0.73260131 0.7254366  0.72572495 0.72654448\n",
      " 0.70889405 0.70992683 0.7104871  0.72130127 0.72098809 0.72145202\n",
      " 0.72093292 0.71965973 0.71986049 0.70377549 0.70350466 0.70386723\n",
      " 0.69575313 0.69469443 0.69420568 0.69575313 0.69469443 0.69420568\n",
      " 0.69172604 0.69167134 0.69194733        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72962113 0.73188046 0.73263223 0.7254366  0.72572495 0.72654448\n",
      " 0.70889405 0.70992683 0.7104871  0.72130127 0.72098809 0.72145202\n",
      " 0.72093292 0.71965973 0.71986049 0.70377549 0.70350466 0.70386723\n",
      " 0.69575313 0.69469443 0.69420568 0.69575313 0.69469443 0.69420568\n",
      " 0.69172604 0.69167134 0.69194733 0.72962113 0.73188046 0.73263223\n",
      " 0.7254366  0.72572495 0.72654448 0.70889405 0.70992683 0.7104871\n",
      " 0.72130127 0.72098809 0.72145202 0.72093292 0.71965973 0.71986049\n",
      " 0.70377549 0.70350466 0.70386723 0.69575313 0.69469443 0.69420568\n",
      " 0.69575313 0.69469443 0.69420568 0.69172604 0.69167134 0.69194733]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========\n",
      "\n",
      "Mejores parámetros encontrados: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "\n",
      "========\n",
      "\n",
      "\n",
      "========\n",
      "\n",
      "Evaluación del modelo Random Forest:\n",
      "MSE: 24291602.5038049\n",
      "MAE: 3208.6106905470288\n",
      "R²: 0.7485992619912492\n",
      "\n",
      "========\n",
      "\n",
      "El modelo se ha guardado en 'models/modelo_random_forest.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# 1. Leer el dataset final\n",
    "df = pd.read_csv('data/archivo_unido_FINAL3.csv')\n",
    "\n",
    "# Convertir la variable objetivo \"Precio\" a numérico y eliminar registros sin precio\n",
    "df['Precio'] = pd.to_numeric(df['Precio'], errors='coerce')\n",
    "df = df.dropna(subset=['Precio'])\n",
    "\n",
    "# 2. Seleccionar la variable objetivo y las variables predictoras\n",
    "y = df['Precio']\n",
    "features = ['Marca', 'Modelo', 'Provincia', 'Año', 'Kilometraje', \n",
    "            'Transmisión', 'Dirección', 'Motor', 'Tracción', 'Color', 'Combustible']\n",
    "X = df[features]\n",
    "\n",
    "# 3. Aplicar Label Encoding a las columnas categóricas y guardar los encoders\n",
    "categorical_cols = ['Marca', 'Modelo', 'Provincia', 'Transmisión', 'Dirección', 'Tracción', 'Color', 'Combustible']\n",
    "X_encoded = X.copy()\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "    encoders[col] = le  # Guardamos el encoder para la columna\n",
    "\n",
    "# Guardar los encoders en un archivo para usarlos en la predicción\n",
    "with open('encoders/encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(encoders, f)\n",
    "\n",
    "# 4. Dividir el dataset en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=89)\n",
    "\n",
    "# 5. Definir el modelo y configurar la búsqueda de hiperparámetros\n",
    "rf = RandomForestRegressor(random_state=82)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 700],\n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='r2', \n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"\")\n",
    "print(\"========\")\n",
    "print(\"\")\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"========\")\n",
    "print(\"\")\n",
    "# Utilizar el mejor estimador encontrado\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# 6. Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\")\n",
    "print(\"========\")\n",
    "print(\"\")\n",
    "print(\"Evaluación del modelo Random Forest:\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R²:\", r2)\n",
    "print(\"\")\n",
    "print(\"========\")\n",
    "print(\"\")\n",
    "# 7. Guardar el modelo entrenado en un archivo\n",
    "joblib.dump(best_rf, 'models/modelo_random_forest.pkl')\n",
    "print(\"El modelo se ha guardado en 'models/modelo_random_forest.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precio predicho: 22377.314666666665\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# 1. Definir la lista de características utilizadas en el entrenamiento\n",
    "features = ['Marca', 'Modelo', 'Provincia', 'Año', 'Kilometraje', \n",
    "            'Transmisión', 'Dirección', 'Motor', 'Tracción', 'Color', 'Combustible']\n",
    "\n",
    "# 2. Crear un registro nuevo (ejemplo). Ajusta los valores según corresponda.\n",
    "nuevo_registro = {\n",
    "    'Marca': ['TOYOTA'],\n",
    "    'Modelo': ['FORTUNER'],\n",
    "    'Provincia': ['GUAYAS'],\n",
    "    'Año': [2011],\n",
    "    'Kilometraje': [150000],\n",
    "    'Transmisión': ['AUTOMATICA'],\n",
    "    'Dirección': ['HIDRAULICA'],\n",
    "    'Motor': [2700],\n",
    "    'Tracción': ['4x4'],\n",
    "    'Color': ['BLANCO'],\n",
    "    'Combustible': ['GASOLINA']\n",
    "}\n",
    "df_nuevo = pd.DataFrame(nuevo_registro)\n",
    "\n",
    "# 3. Cargar los encoders guardados y aplicarlos a las columnas categóricas\n",
    "categorical_cols = ['Marca', 'Modelo', 'Provincia', 'Transmisión', 'Dirección', 'Tracción', 'Color', 'Combustible']\n",
    "\n",
    "with open('encoders/encoders.pkl', 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "\n",
    "df_nuevo_encoded = df_nuevo.copy()\n",
    "for col in categorical_cols:\n",
    "    # Se utiliza el encoder guardado para transformar el registro nuevo\n",
    "    df_nuevo_encoded[col] = encoders[col].transform(df_nuevo_encoded[col].astype(str))\n",
    "\n",
    "# 4. Cargar el modelo entrenado\n",
    "modelo_rf = joblib.load('models/modelo_random_forest.pkl')\n",
    "\n",
    "# 5. Realizar la predicción asegurándose de que el orden de las columnas coincide con 'features'\n",
    "precio_predicho = modelo_rf.predict(df_nuevo_encoded[features])\n",
    "print(\"Precio predicho:\", precio_predicho[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================================\n",
    "#MODELO XGBOOST\n",
    "#=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "\n",
      "========\n",
      "\n",
      "Mejores parámetros encontrados: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 700, 'subsample': 0.9}\n",
      "\n",
      "========\n",
      "\n",
      "\n",
      "========\n",
      "\n",
      "Evaluación del modelo XGBoost:\n",
      "MSE: 17756015.678265683\n",
      "MAE: 2593.7936584943363\n",
      "R²: 0.8162379182307241\n",
      "\n",
      "========\n",
      "\n",
      "El modelo se ha guardado en 'modelo_xgboost.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# 1. Leer el dataset final\n",
    "df = pd.read_csv('data/archivo_unido_FINAL3.csv')\n",
    "\n",
    "# Convertir la variable objetivo \"Precio\" a numérico y eliminar registros sin precio\n",
    "df['Precio'] = pd.to_numeric(df['Precio'], errors='coerce')\n",
    "df = df.dropna(subset=['Precio'])\n",
    "\n",
    "# 2. Seleccionar la variable objetivo y las variables predictoras\n",
    "y = df['Precio']\n",
    "features = ['Marca', 'Modelo', 'Provincia', 'Año', 'Kilometraje', \n",
    "            'Transmisión', 'Dirección', 'Motor', 'Tracción', 'Color', 'Combustible']\n",
    "X = df[features]\n",
    "\n",
    "# 3. Aplicar Label Encoding a las columnas categóricas y guardar los encoders\n",
    "categorical_cols = ['Marca', 'Modelo', 'Provincia', 'Transmisión', 'Dirección', 'Tracción', 'Color', 'Combustible']\n",
    "X_encoded = X.copy()\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "    encoders[col] = le  # Guardamos el encoder para la columna\n",
    "\n",
    "# Guardar los encoders en un archivo para usarlos en la predicción\n",
    "with open('encoders/encoders_xgboost.pkl', 'wb') as f:\n",
    "    pickle.dump(encoders, f)\n",
    "\n",
    "# 4. Dividir el dataset en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=89)\n",
    "\n",
    "# 5. Definir el modelo XGBoost y configurar la búsqueda de hiperparámetros\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=82)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 700],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='r2', \n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n========\\n\")\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"\\n========\\n\")\n",
    "\n",
    "# Utilizar el mejor estimador encontrado\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# 6. Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n========\\n\")\n",
    "print(\"Evaluación del modelo XGBoost:\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R²:\", r2)\n",
    "print(\"\\n========\\n\")\n",
    "\n",
    "# 7. Guardar el modelo entrenado en un archivo\n",
    "joblib.dump(best_xgb, 'models/modelo_xgboost.pkl')\n",
    "print(\"El modelo se ha guardado en 'modelo_xgboost.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precio predicho: 8893.264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# 1. Definir la lista de características utilizadas en el entrenamiento\n",
    "features = ['Marca', 'Modelo', 'Provincia', 'Año', 'Kilometraje', \n",
    "            'Transmisión', 'Dirección', 'Motor', 'Tracción', 'Color', 'Combustible']\n",
    "\n",
    "# 2. Crear un registro nuevo (ejemplo)\n",
    "nuevo_registro = {\n",
    "    'Marca': ['TOYOTA'],\n",
    "    'Modelo': ['FORTUNER'],\n",
    "    'Provincia': ['GUAYAS'],\n",
    "    'Año': [2011],\n",
    "    'Kilometraje': [150000],\n",
    "    'Transmisión': ['AUTOMATICA'],\n",
    "    'Dirección': ['HIDRAULICA'],\n",
    "    'Motor': [2700],\n",
    "    'Tracción': ['4x4'],\n",
    "    'Color': ['BLANCO'],\n",
    "    'Combustible': ['GASOLINA']\n",
    "}\n",
    "nuevo_registro = {\n",
    "    'Marca': ['CHEVROLET'],\n",
    "    'Modelo': ['AVEO ACTIVO'],\n",
    "    'Provincia': ['PICHINCHA'],\n",
    "    'Año': [2011],\n",
    "    'Kilometraje': [150000],\n",
    "    'Transmisión': ['MANUAL'],\n",
    "    'Dirección': ['MECANICA'],\n",
    "    'Motor': [1600],\n",
    "    'Tracción': ['4x2'],\n",
    "    'Color': ['AMARILLO'],\n",
    "    'Combustible': ['GASOLINA']\n",
    "}\n",
    "df_nuevo = pd.DataFrame(nuevo_registro)\n",
    "\n",
    "# 3. Cargar los encoders guardados y aplicarlos a las columnas categóricas\n",
    "categorical_cols = ['Marca', 'Modelo', 'Provincia', 'Transmisión', 'Dirección', 'Tracción', 'Color', 'Combustible']\n",
    "\n",
    "with open('encoders/encoders_xgboost.pkl', 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "\n",
    "df_nuevo_encoded = df_nuevo.copy()\n",
    "for col in categorical_cols:\n",
    "    df_nuevo_encoded[col] = encoders[col].transform(df_nuevo_encoded[col].astype(str))\n",
    "\n",
    "# 4. Cargar el modelo entrenado\n",
    "modelo_xgb = joblib.load('models/modelo_xgboost.pkl')\n",
    "\n",
    "# 5. Realizar la predicción asegurándose de que el orden de las columnas coincide con 'features'\n",
    "precio_predicho = modelo_xgb.predict(df_nuevo_encoded[features])\n",
    "print(\"Precio predicho:\", precio_predicho[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=======================22439.43==20299.37===19956.922===17580.81===========================================================\n",
    "#MODELO CatBoostRegressor\n",
    "#=========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install --upgrade catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18816904.171669405\n",
      "MAE: 2906.343191514214\n",
      "R²: 0.8052584799600331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/modelo_catboost.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('data/archivo_unido_FINAL3.csv')\n",
    "df['Precio'] = pd.to_numeric(df['Precio'], errors='coerce')\n",
    "df = df.dropna(subset=['Precio'])\n",
    "\n",
    "# Variables\n",
    "y = df['Precio']\n",
    "features = ['Marca', 'Modelo', 'Provincia', 'Año', 'Kilometraje', 'Transmisión', 'Dirección', 'Motor', 'Tracción', 'Color', 'Combustible']\n",
    "X = df[features]\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=89)\n",
    "\n",
    "# Definir modelo CatBoost\n",
    "cat_model = CatBoostRegressor(iterations=500, depth=10, learning_rate=0.05, loss_function='RMSE', random_seed=82)\n",
    "\n",
    "# Entrenar modelo (CatBoost maneja automáticamente variables categóricas)\n",
    "cat_model.fit(X_train, y_train, cat_features=['Marca', 'Modelo', 'Provincia', 'Transmisión', 'Dirección', 'Tracción', 'Color', 'Combustible'], verbose=False)\n",
    "\n",
    "# Evaluación\n",
    "y_pred = cat_model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(cat_model, 'models/modelo_catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚗 Precio predicho del vehículo: 18179.386456884837\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle\n",
    "\n",
    "# 1. Definir la lista de características utilizadas en el entrenamiento\n",
    "features = ['Marca', 'Modelo', 'Provincia', 'Año', 'Kilometraje', \n",
    "            'Transmisión', 'Dirección', 'Motor', 'Tracción', 'Color', 'Combustible']\n",
    "\n",
    "# 2. Crear un registro nuevo (ejemplo)\n",
    "nuevo_registro = {\n",
    "    'Marca': ['TOYOTA'],\n",
    "    'Modelo': ['FORTUNER'],\n",
    "    'Provincia': ['PICHINCHA'],\n",
    "    'Año': [2011],\n",
    "    'Kilometraje': [150000],\n",
    "    'Transmisión': ['AUTOMATICA'],\n",
    "    'Dirección': ['HIDRAULICA'],\n",
    "    'Motor': [2700],\n",
    "    'Tracción': ['4x4'],\n",
    "    'Color': ['BLANCO'],\n",
    "    'Combustible': ['GASOLINA']\n",
    "}\n",
    "df_nuevo = pd.DataFrame(nuevo_registro)\n",
    "\n",
    "# 3. Cargar los encoders guardados y aplicar a las columnas categóricas\n",
    "categorical_cols = ['Marca', 'Modelo', 'Provincia', 'Transmisión', 'Dirección', 'Tracción', 'Color', 'Combustible']\n",
    "\n",
    "with open('encoders/encoders.pkl', 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "\n",
    "df_nuevo_encoded = df_nuevo.copy()\n",
    "for col in categorical_cols:\n",
    "    if col in encoders:\n",
    "        df_nuevo_encoded[col] = encoders[col].transform(df_nuevo_encoded[col].astype(str))\n",
    "    else:\n",
    "        print(f\"⚠️ Advertencia: No se encontró encoder para {col}\")\n",
    "\n",
    "# 4. Cargar el modelo entrenado\n",
    "modelo_catboost = joblib.load('models/modelo_catboost.pkl')\n",
    "\n",
    "# 5. Realizar la predicción asegurándose de que el orden de las columnas coincide con 'features'\n",
    "precio_predicho = modelo_catboost.predict(df_nuevo_encoded[features])\n",
    "\n",
    "print(\"🚗 Precio predicho del vehículo:\", precio_predicho[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
